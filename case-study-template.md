# Case-study оптимизации

## Актуальная проблема
В нашем проекте возникла серьёзная проблема.

Необходимо было обработать файл с данными, чуть больше ста мегабайт.

У нас уже была программа на `ruby`, которая умела делать нужную обработку.

Она успешно работала на файлах размером пару мегабайт, но для большого файла она работала слишком долго, и не было понятно, закончит ли она вообще работу за какое-то разумное время.

Я решил исправить эту проблему, оптимизировав эту программу.

## Формирование метрики
Для того, чтобы понимать, дают ли мои изменения положительный эффект на быстродействие программы я придумал использовать такую метрику: в первую очередь нас интересует время работы программы, пока она отрабатывает за "бесконечное время" оптимизация памяти преждевременна
 Хочу не потеряв в удобности поддержки кода оптимизировать код чтобы программа работала хотя бы в пределах минуты

## Гарантия корректности работы оптимизированной программы
Программа поставлялась с тестом. Выполнение этого теста позволяет не допустить изменения логики программы при оптимизации.

## Feedback-Loop
Для того, чтобы иметь возможность быстро проверять гипотезы я выстроил эффективный `feedback-loop`, который позволил мне получать обратную связь по эффективности сделанных изменений за *время, которое у вас получилось*

Вот как я построил `feedback_loop`: *как вы построили feedback_loop*

## Вникаем в детали системы, чтобы найти 20% точек роста
Первой очевидной точкой раста на первый взгляд кажется чтение файла, но даже в первоначальном состоянии это
занимает около 1,5 секунды что в рамках работы всей программы не так много.

Для того, чтобы найти "точки роста" для оптимизации я воспользовался
- Посмотрел с помощью benchmark как растет потребление памяти при обработке 100, 1000, 10000, 50000 строк из файла, без построения отчета
получились такие результаты:
100 - 0.0003s
1000 - 0.005s
10000 - 0.5s
50000 - 6.02s программа не отработала
100000 - 21.8945s программа не отработала
Окей, время работы растет очень сильно, но 6 секунд на парсинг строк и в несколько раз больше времени на построение отчета говорят что
основные проблемы не в парсинге строк. Этот момент тоже надо оптимизировать, но позже, пока приоритеты на оптимизацию выглядят так

1. ???
2. Парсинг строк
3. Потоковое чтение из файла

Проверяем каждый этап построения отчета на массиве в 10к строк
Больше всего времени уходит на построение массива из инстанос класса User
парсинг строк - 0.4936
поиск уникальных браузеров - 0.0604
Подсчёт количества уникальных браузеров - 0.0604
Перечислить уникальные браузеры в алфавитном порядке через запятую и капсом - 0.005
сколько всего сессий + 0.1847
сколько всего времени + 0.0638
самая длинная сессия + 0.0067
браузеры через запятую + 0.0104
Хоть раз использовал IE? + 0.0075
Всегда использовал только Хром? + 0.006
даты сессий в порядке убывания через запятую + 0.0596

массив из User - 1.4759

Проверяем на 20000 строк
парсинг строк - 0.9174
поиск уникальных браузеров - 0.1074
Подсчёт количества уникальных браузеров - 0.0604
Перечислить уникальные браузеры в алфавитном порядке через запятую и капсом - 0.009
сколько всего сессий + 0.0047
сколько всего времени + 0.0131
самая длинная сессия + 0.0128
браузеры через запятую + 0.0232
Хоть раз использовал IE? + 0.018
Всегда использовал только Хром? + 0.0135
даты сессий в порядке убывания через запятую + 0.1147

массив User = 9.5216


Очевидная проблема в генерации массива инстансов User.
Список кандидатов на оптимизацию выглядит так
1. Построение массива юзеров
2. Парсинг строк
3. Построчное чтение файла
Выносим эту генерацию в отдельную функцию для удобства профилирования и смотрим на потрбление памяти


Вот какие проблемы удалось найти и решить

### Ваша находка №1
О вашей находке №1

### Ваша находка №2
О вашей находке №2

### Ваша находка №X
О вашей находке №X

## Результаты
В результате проделанной оптимизации наконец удалось обработать файл с данными.
Удалось улучшить метрику системы с *того, что у вас было в начале, до того, что получилось в конце*

*Какими ещё результами можете поделиться*

## Защита от регресса производительности
Для защиты от потери достигнутого прогресса при дальнейших изменениях программы сделано *то, что вы для этого сделали*
